## Evalution

The environment hosting the benchmark is exposed via VNC and various tool calls that wrap X11 commands.

First, create a class inheriting `Agent` from `eval/uitask/computer_use/act.py` and implement
`def act(self)` such that `act` will perform a single agent iteration and return whether
or not the agent should stop. The evaluation will call `run(max_steps: int, record: bool)` on the
`Agent` instance, which in turn calls `self.act()` iteratively until `max_steps` iterations are
performed or `act()` returns `True`. In `act()` implement the mapping for the following actions

## Running the evaluation

Review the sections below to understand how to setup the evaluation. Once setup run the following executions
to build and run the job

```
> cd DeterministicBenchmark/eval
> uv venv --python 3.12
> uv sync --frozen --all-groups
> uv run uitask-container build
> uv run uitask/evaluate/byom/custom/run.py # defined below
```

### Available environment interaction tools
```
# Moves mouse to position
* mouse_move(self, position: Position)

# Click a specific mouse button N times at position - clicks at current position if None
* mouse_click(self, action: MouseClickAction)

# Click a specific mouse button from start to end position
* mouse_drag(self, action: MouseDragAction)

# Scroll the mouse in a direction N times from a starting position
* mouse_scroll(self, action: ScrollAction)

# Emit single key or sequence of keys. If multiple keys, it will all held in order
* press_keys(self, keys: Sequence[str])

# Emit text
* type_text(self, text: str)

# Navigate page by emitting alt + arrow direction
* page_navigation(self, direction: Literal["forward", "back"])

# Wait for loading
* wait(self, duration: float)

# Mark the task as done
* finish(self, params: dict[str, Any] | None = None)
```

### Available tools
```
# Get a base64 screenshot
* screenshot(self)

# Get the current os resolution
* client_resolution(self)
```

We have included a sample implementation of the UiPath Screenplay agent wrapper `eval/uitask/computer_use/byom/uipath/agent.py`
but you can follow the sample below assuming `eval/uitask/computer_use/byom/custom/agent.py`

```
from ...act import Agent

class CustomAgent(Agent):
    ... # Some initialization for self.state to track messages state throughout execution

    def act(self) -> bool:
        response = call_model_for_next_action(self.state).json()
        self.state.append(response)

        match response["action"]:
            case "mouse_move":
                self.mouse_click(Position(response["param"]["x"], response["param"]["y"]))
            case "wait":
                self.wait(response["param"]["duration"])
            case ...
```

Then you can build a custom evaluation script to take advantage of a Dask orchestrated execution of the tasks on docker containers.
By specifying `--max-steps`, `--num-workers`, `--threads-per-worker`, you can launch `num_workers * threads_per_worker` parallel
instances of docker with your agent attached to the environment.

We included a sample evaluation execution script for the UiPath Screenplay agent wrapper `eval/uitask/evaluate/byom/uipath/screenplay.py`
but you can follow the sample below assuming `eval/uitask/evaluate/byom/custom/run.py`

`run_tasks` requires the various screen resolution sizes to be ran and an implementation of the protocol `AgentBuilder` implemented in
`eval/uitask/evaluate/run.py` that takes def f(`task: Task`, `output_dir: Path`, `vnc_port: int`, `cdp_port: int`) -> Agent

The `vnc_port` and `cdp_port` are autogenerated - the function just needs to take it and pass it so that the `Agent` class can be initialized.

We provided a list of tasks `deterministic_bench.json` that can be passed to `--task-file`
```
import typer

from pathlib import Path
from uitask.computer_use import CustomAgent
from ...run import ScreenResolution, Task, run_tasks

app = typer.Typer()

@app.command()
def evaluate(
    output_dir: Path = typer.Option(..., help="Output directory to persist results"),
    task_file: Path = typer.Option(..., help="Task file"),
    max_steps: int = typer.Option(default=50, help="Number of maximum steps allowed",)
    num_workers: int = typer.Option(default=1, help="Number of dask workers"),
    threads_per_worker: int = typerOption(default=5, help=Number of threads per dask workers"),
    resolution: list[str] = typer.Option(default=["1920_1080"], help="Res to run"),
    record: bool = typer.Option(default=False, help="Generate a video recording of the trajectory"),
):
    def agent_builder(task: Task, task_output_dir: Path, vnc_port: int, cdp_port: int):
        return CustomAgent(
            task=task.task,
            output_dir=task_output_dir,
            vnc_port=vnc_port,
            cdp_port=cdp_port
        )

    run_tasks(
        agent_builder=agent_builder,
        tasks_file=task_file,
        output_dir=output_dir,
        resolutions=resolutions,
        record=record,
        max_steps=max_steps,
        num_workers=num_workers,
        threads_per_worker=threads_per_worker
    )

if __name__ == "__main__":
    app()
```